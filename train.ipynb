{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 股票预测模型工作流\n",
                "\n",
                "---\n",
                "### 工作流说明\n",
                "1.  **阶段零 (Setup)**: 导入库、加载配置。\n",
                "2.  **阶段一 (Data Pipeline)**: 独立运行。负责处理并保存数据，生成 L2 特征数据缓存。\n",
                "3.  **阶段二 (Model Pipeline)**: 独立运行。包含三个子步骤：\n",
                "    - **2.1 HPO**: 自动调参。\n",
                "    - **2.2 (预处理)**: 智能地加载或生成 L3 预处理数据缓存\n",
                "    - **2.3 (模型训练)**: 使用 L3 缓存进行高效的模型训练。\n",
                "    - **2.4 (评估)**: 对训练结果进行聚合与可视化。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. 通用设置与导入"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "d:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\\main_train.py:13: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
                        "  from tqdm.autonotebook import tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- 正在初始化环境：加载配置与模块... ---\n",
                        "INFO: 底层并行计算库线程数已设置为: 4\n",
                        "INFO: 项目模块导入成功。\n",
                        "SUCCESS: 配置已从 'configs/config.yaml' 加载。\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "from pathlib import Path\n",
                "import matplotlib.pyplot as plt\n",
                "import seaborn as sns\n",
                "\n",
                "# 设置 Matplotlib 样式 (可以在 main_train 外部设置)\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
                "plt.rcParams['axes.unicode_minus'] = False\n",
                "\n",
                "# --- 动态导入 main_train ---\n",
                "project_root = str(Path().resolve())\n",
                "if project_root not in sys.path:\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "# 从我们统一的核心引擎中导入所有需要的函数和模块\n",
                "from main_train import (\n",
                "    run_load_config_and_modules,\n",
                "    run_all_data_pipeline,\n",
                "    run_preprocess_l3_cache,\n",
                "    run_hpo_train,\n",
                "    run_all_models_train,\n",
                "    run_performance_evaluation,\n",
                "    run_results_visualization\n",
                ")\n",
                "\n",
                "# --- 加载全局配置和模块 ---\n",
                "# 在 Notebook 的生命周期中，我们只加载一次\n",
                "config, modules = run_load_config_and_modules()\n",
                "\n",
                "if not (config and modules):\n",
                "    raise RuntimeError(\"环境初始化失败，请检查配置文件路径和模块导入。\")"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **阶段一：数据准备与特征工程**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- INFO: 日期模式 -> 使用最新日期 ---\n",
                        "=== 阶段一：数据准备与特征工程 ===\n",
                        "INFO: 已启用动态日期模式，将使用今天的日期 '2025-10-24' 作为 end_date。\n",
                        "      计算得出的 start_date 为: 2010-10-24\n",
                        "INFO: 正在尝试登录 Baostock...\n",
                        "login success!\n",
                        "INFO: Baostock API 登录成功。\n",
                        "INFO: 未在配置中提供有效的 Tushare Token，将跳过 Tushare 相关数据。\n",
                        "开始执行数据管道协调任务...\n",
                        "INFO: 正在根据 'end_date' 和 'data_lookback_years' 动态计算 'start_date'...\n",
                        "      计算得出的 start_date 为: 2010-10-24，已更新到本次运行的全局配置中。\n",
                        "INFO: 特征文件已存在于 data\\processed\\000100.SZ\\5de9c41e74af\\features.pkl，跳过 TCL科技 (000100.SZ) 的数据处理。\n",
                        "INFO: 特征文件已存在于 data\\processed\\000426.SZ\\f6589d437087\\features.pkl，跳过 兴业矿业 (000426.SZ) 的数据处理。\n",
                        "INFO: 特征文件已存在于 data\\processed\\002083.SZ\\e54a78b13e0b\\features.pkl，跳过 孚日股份 (002083.SZ) 的数据处理。\n",
                        "INFO: 特征文件已存在于 data\\processed\\000150.SZ\\78537e2c1be4\\features.pkl，跳过 宜华健康 (000150.SZ) 的数据处理。\n",
                        "INFO: 特征文件已存在于 data\\processed\\300013.SZ\\681eb130ef3c\\features.pkl，跳过 新宁物流 (300013.SZ) 的数据处理。\n",
                        "INFO: 特征文件已存在于 data\\processed\\300242.SZ\\f49537315712\\features.pkl，跳过 佳云科技 (300242.SZ) 的数据处理。\n",
                        "INFO: 特征文件已存在于 data\\processed\\002006.SZ\\8e20872224e0\\features.pkl，跳过 精功科技 (002006.SZ) 的数据处理。\n",
                        "INFO: 特征文件已存在于 data\\processed\\300242.SZ\\f49537315712\\features.pkl，跳过 佳云科技 (300242.SZ) 的数据处理。\n",
                        "\n",
                        "所有股票的特征文件均已存在。无需执行数据处理流水线。\n",
                        "logout success!\n",
                        "INFO: Baostock API 已成功登出.\n",
                        "--- 阶段 1 成功完成。 ---\n"
                    ]
                }
            ],
            "source": [
                "USE_LATEST_DATE = True\n",
                "if config and modules:\n",
                "    print(f\"--- INFO: 日期模式 -> {'使用最新日期' if USE_LATEST_DATE else '使用配置文件中的固定日期'} ---\")\n",
                "    \n",
                "    # (核心修改) 将开关状态传递给核心引擎函数\n",
                "    run_all_data_pipeline(config, modules, use_today_as_end_date=USE_LATEST_DATE)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **阶段二：模型训练与评估**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 数据预加载与全局预处理 (L3 缓存)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "\n",
                        "================================================================================\n",
                        "=== 工作流阶段 2.1：为模型预处理数据 (L3 缓存) ===\n",
                        "================================================================================\n",
                        "WARNNING: 加载 L3 缓存失败: 。将重新预处理。\n",
                        "INFO: L3 缓存不存在、为空或被强制重建。开始执行预处理流程...\n",
                        "\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "67a43b8dc2684f81b12cd7400330cb7b",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "正在预处理股票:   0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                }
            ],
            "source": [
                "if config and modules:\n",
                "    # 调用核心引擎中的预处理函数\n",
                "    # force_reprocess=True/False 可以方便地控制是否重建缓存\n",
                "    global_data_cache = run_preprocess_l3_cache(config, modules, force_reprocess=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 超参数优化"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 同样，可以通过一个简单的开关来控制是否运行\n",
                "RUN_HPO = False\n",
                "\n",
                "if RUN_HPO and config and modules and 'global_data_cache' in locals():\n",
                "    # 调用核心引擎中的 HPO 函数\n",
                "    # HPO 的结果会自动更新到内存中的 config 字典里\n",
                "    run_hpo_train(config, modules, global_data_cache)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 模型训练"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== 工作流阶段 2.3：训练所有模型 ===\n",
                        "\n",
                        "--- 2.3.1 基础模型训练 ---\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "cdc05a6557f2447f8d2319ce5ed087f3",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "训练基础模型:   0%|          | 0/8 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- 开始为 TCL科技 (000100.SZ) 进行 LGBM 模型训练 ---\n",
                        "INFO: 强制重训已开启，将删除所有旧的构件...\n",
                        "INFO: 开始对 TCL科技 (000100.SZ) 进行跨 64 folds 的前向验证...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "6b5e51ec4177401099f97bb236786891",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "正在 TCL科技 上训练 LGBM:   0%|          | 0/64 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "INFO: 滚动训练成功完成，准备训练最终模型。\n",
                        "INFO: 正在训练最终模型...\n",
                        "SUCCESS: 新版本 (20251024) 模型已保存: lgbm_model_20251024.pkl\n",
                        "INFO: 整个训练流程（包括最终模型）成功完成，已移除进度文件。\n",
                        "--- 开始为 TCL科技 (000100.SZ) 进行 LSTM 模型训练 ---\n",
                        "INFO: 强制重训已开启，将删除所有旧的构件...\n",
                        "INFO: PyTorch LSTMBuilder initialized with device: CUDA\n",
                        "INFO: DataLoader will use 8 parallel workers.\n",
                        "INFO: Automatic Mixed Precision (AMP) is ENABLED (float16).\n",
                        "INFO: 开始对 TCL科技 (000100.SZ) 进行跨 64 folds 的前向验证...\n"
                    ]
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0f5ecb0f74c64fdd8daa75ce8944879d",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "正在 TCL科技 上训练 LSTM:   0%|          | 0/64 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "data": {
                        "application/vnd.jupyter.widget-view+json": {
                            "model_id": "0a9d46b3f6824374a0a4254d58fcaa79",
                            "version_major": 2,
                            "version_minor": 0
                        },
                        "text/plain": [
                            "    - Epochs (LSTM):   0%|          | 0/75 [00:00<?, ?it/s]"
                        ]
                    },
                    "metadata": {},
                    "output_type": "display_data"
                },
                {
                    "ename": "RuntimeError",
                    "evalue": "DataLoader worker (pid(s) 26180, 29652, 27456, 29568, 31360, 27576, 27680, 7836) exited unexpectedly",
                    "output_type": "error",
                    "traceback": [
                        "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
                        "\u001b[31mEmpty\u001b[39m                                     Traceback (most recent call last)",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1285\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1284\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1285\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_data_queue\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1286\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mTrue\u001b[39;00m, data)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32mD:\\Program_File\\Python\\3.13.0\\Lib\\queue.py:212\u001b[39m, in \u001b[36mQueue.get\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m    211\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m remaining <= \u001b[32m0.0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m212\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m Empty\n\u001b[32m    213\u001b[39m \u001b[38;5;28mself\u001b[39m.not_empty.wait(remaining)\n",
                        "\u001b[31mEmpty\u001b[39m: ",
                        "\nThe above exception was the direct cause of the following exception:\n",
                        "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
                        "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m config \u001b[38;5;129;01mand\u001b[39;00m modules \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mglobal_data_cache\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlocals\u001b[39m():\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# 调用核心引擎中的模型训练函数\u001b[39;00m\n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# 同样可以通过开关控制是否强制重训\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     all_ic_history = \u001b[43mrun_all_models_train\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodules\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mglobal_data_cache\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_retrain_base\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_retrain_fuser\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\\main_train.py:919\u001b[39m, in \u001b[36mrun_all_models_train\u001b[39m\u001b[34m(config, modules, global_data_cache, force_retrain_base, force_retrain_fuser, run_fusion)\u001b[39m\n\u001b[32m    910\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m    912\u001b[39m run_config = {\n\u001b[32m    913\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mglobal_settings\u001b[39m\u001b[33m'\u001b[39m: global_settings, \u001b[33m'\u001b[39m\u001b[33mstrategy_config\u001b[39m\u001b[33m'\u001b[39m: strategy_config,\n\u001b[32m    914\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mdefault_model_params\u001b[39m\u001b[33m'\u001b[39m: default_model_params, \u001b[33m'\u001b[39m\u001b[33mstocks_to_process\u001b[39m\u001b[33m'\u001b[39m: [stock_info],\n\u001b[32m    915\u001b[39m     \u001b[33m'\u001b[39m\u001b[33mfull_df_for_final_model\u001b[39m\u001b[33m'\u001b[39m: full_df\n\u001b[32m    916\u001b[39m }\n\u001b[32m    918\u001b[39m ic_history = run_training_for_ticker(\n\u001b[32m--> \u001b[39m\u001b[32m919\u001b[39m     preprocessed_folds=preprocessed_folds,\n\u001b[32m    920\u001b[39m     ticker=ticker, model_type=model_type, config=run_config, \n\u001b[32m    921\u001b[39m     force_retrain=force_retrain_base, keyword=keyword\n\u001b[32m    922\u001b[39m )\n\u001b[32m    924\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ic_history \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ic_history.empty:\n\u001b[32m    925\u001b[39m     ic_history[\u001b[33m'\u001b[39m\u001b[33mticker\u001b[39m\u001b[33m'\u001b[39m] = ticker\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\\model\\build_models.py:158\u001b[39m, in \u001b[36mrun_training_for_ticker\u001b[39m\u001b[34m(preprocessed_folds, ticker, model_type, config, force_retrain, keyword)\u001b[39m\n\u001b[32m    155\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, fold_data \u001b[38;5;129;01min\u001b[39;00m fold_iterator:\n\u001b[32m    156\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i < start_fold_idx: \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     artifacts, ic_series_fold, oof_fold_df, fold_stats = \u001b[43mbuilder\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_and_evaluate_fold\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    159\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_df\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcached_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfold_data\u001b[49m\n\u001b[32m    160\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    162\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ic_series_fold \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m ic_series_fold.empty:\n\u001b[32m    163\u001b[39m         ic_series_fold.to_csv(ic_history_path, mode=\u001b[33m'\u001b[39m\u001b[33ma\u001b[39m\u001b[33m'\u001b[39m, header=\u001b[38;5;129;01mnot\u001b[39;00m ic_history_path.exists(), index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\\model\\builders\\lstm_builder.py:133\u001b[39m, in \u001b[36mLSTMBuilder.train_and_evaluate_fold\u001b[39m\u001b[34m(self, train_df, val_df, cached_data)\u001b[39m\n\u001b[32m    131\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[32m    132\u001b[39m     model.train()\n\u001b[32m--> \u001b[39m\u001b[32m133\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    134\u001b[39m \u001b[43m        \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_batch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    135\u001b[39m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mset_to_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:734\u001b[39m, in \u001b[36m_BaseDataLoaderIter.__next__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    731\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    732\u001b[39m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[32m    733\u001b[39m     \u001b[38;5;28mself\u001b[39m._reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m734\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    735\u001b[39m \u001b[38;5;28mself\u001b[39m._num_yielded += \u001b[32m1\u001b[39m\n\u001b[32m    736\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    737\u001b[39m     \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable\n\u001b[32m    738\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    739\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._num_yielded > \u001b[38;5;28mself\u001b[39m._IterableDataset_len_called\n\u001b[32m    740\u001b[39m ):\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1492\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._next_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1489\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._process_data(data, worker_id)\n\u001b[32m   1491\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._shutdown \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m._tasks_outstanding > \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1492\u001b[39m idx, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1493\u001b[39m \u001b[38;5;28mself\u001b[39m._tasks_outstanding -= \u001b[32m1\u001b[39m\n\u001b[32m   1494\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._dataset_kind == _DatasetKind.Iterable:\n\u001b[32m   1495\u001b[39m     \u001b[38;5;66;03m# Check for _IterableDatasetStopIteration\u001b[39;00m\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1444\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._get_data\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1442\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory:\n\u001b[32m   1443\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m._pin_memory_thread.is_alive():\n\u001b[32m-> \u001b[39m\u001b[32m1444\u001b[39m         success, data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_try_get_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1445\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m success:\n\u001b[32m   1446\u001b[39m             \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
                        "\u001b[36mFile \u001b[39m\u001b[32md:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:1298\u001b[39m, in \u001b[36m_MultiProcessingDataLoaderIter._try_get_data\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1296\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(failed_workers) > \u001b[32m0\u001b[39m:\n\u001b[32m   1297\u001b[39m     pids_str = \u001b[33m\"\u001b[39m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m.join(\u001b[38;5;28mstr\u001b[39m(w.pid) \u001b[38;5;28;01mfor\u001b[39;00m w \u001b[38;5;129;01min\u001b[39;00m failed_workers)\n\u001b[32m-> \u001b[39m\u001b[32m1298\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1299\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataLoader worker (pid(s) \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpids_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m) exited unexpectedly\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1300\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m   1301\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, queue.Empty):\n\u001b[32m   1302\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n",
                        "\u001b[31mRuntimeError\u001b[39m: DataLoader worker (pid(s) 26180, 29652, 27456, 29568, 31360, 27576, 27680, 7836) exited unexpectedly"
                    ]
                }
            ],
            "source": [
                "if config and modules and 'global_data_cache' in locals():\n",
                "    # 调用核心引擎中的模型训练函数\n",
                "    # 同样可以通过开关控制是否强制重训\n",
                "    all_ic_history = run_all_models_train(\n",
                "        config, \n",
                "        modules, \n",
                "        global_data_cache, \n",
                "        force_retrain_base=True, \n",
                "        force_retrain_fuser=True\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 结果聚合、评估与可视化"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "if config and modules and 'all_ic_history' in locals() and all_ic_history:\n",
                "    # 调用核心引擎中的评估和可视化函数\n",
                "    evaluation_summary, backtest_summary, final_eval_df = run_performance_evaluation(config, modules, all_ic_history)\n",
                "    \n",
                "    # 只有在有结果时才进行可视化\n",
                "    if evaluation_summary is not None or backtest_summary is not None:\n",
                "        run_results_visualization(config, modules, evaluation_summary, backtest_summary, final_eval_df)\n",
                "    else: print('无可视化结果')"
            ]
        }
    ],
    "metadata": {
        "...": "...",
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
