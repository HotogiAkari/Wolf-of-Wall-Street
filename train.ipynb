{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# 股票预测模型工作流\n",
                "\n",
                "---\n",
                "### 工作流说明\n",
                "1.  **阶段零 (Setup)**: 导入库、加载配置。\n",
                "2.  **阶段一 (Data Pipeline)**: 独立运行。负责处理并保存数据，生成 L2 特征数据缓存。\n",
                "3.  **阶段二 (Model Pipeline)**: 独立运行。包含三个子步骤：\n",
                "    - **2.1 HPO**: 自动调参。\n",
                "    - **2.2 (预处理)**: 智能地加载或生成 L3 预处理数据缓存\n",
                "    - **2.3 (模型训练)**: 使用 L3 缓存进行高效的模型训练。\n",
                "    - **2.4 (评估)**: 对训练结果进行聚合与可视化。"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 0. 通用设置与导入"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\Akari\\AppData\\Local\\Temp\\ipykernel_32720\\2077795851.py:9: TqdmExperimentalWarning: Using `tqdm.autonotebook.tqdm` in notebook mode. Use `tqdm.tqdm` instead to force console mode (e.g. in jupyter console)\n",
                        "  from tqdm.autonotebook import tqdm\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "将项目根目录添加到 sys.path: D:\\Project\\Command\\Python\\Neural\\Wolf_of_Wall_Street\n",
                        "--- 正在为 Notebook 加载和合并所有配置文件 ---\n",
                        "  - 主配置 'config.yaml' 已加载。\n",
                        "  - 子配置 'data\\default.yaml' 已加载到 'data' 组。\n",
                        "  - 子配置 'features\\default.yaml' 已加载到 'features' 组。\n",
                        "  - 子配置 'labeling\\raw_return.yaml' 已加载到 'labeling' 组。\n",
                        "  - 子配置 'model\\lgbm.yaml' 已加载到 'model' 组。\n",
                        "  - 子配置 'hpo\\default.yaml' 已加载到 'hpo' 组。\n",
                        "  - 子配置 'backtest\\default.yaml' 已加载到 'backtest' 组。\n",
                        "  - 子配置 'application\\default.yaml' 已加载到 'application' 组。\n",
                        "--- 所有配置文件合并成功 ---\n",
                        "--- 正在加载所有项目模块... ---\n",
                        "INFO: 项目模块导入成功。\n"
                    ]
                }
            ],
            "source": [
                "import sys\n",
                "import json\n",
                "import yaml\n",
                "from pathlib import Path\n",
                "import matplotlib.pyplot as plt\n",
                "import pandas as pd\n",
                "import torch\n",
                "import joblib\n",
                "from tqdm.autonotebook import tqdm\n",
                "from sklearn.preprocessing import StandardScaler\n",
                "from utils.config_utils import load_and_merge_configs_for_notebook\n",
                "\n",
                "# --- 1. 环境与路径设置 ---\n",
                "project_root = str(Path().resolve())\n",
                "if project_root not in sys.path:\n",
                "    print(f\"将项目根目录添加到 sys.path: {project_root}\")\n",
                "    sys.path.append(project_root)\n",
                "\n",
                "plt.style.use('seaborn-v0_8-whitegrid')\n",
                "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
                "plt.rcParams['axes.unicode_minus'] = False\n",
                "\n",
                "# --- 2.  加载配置和所有模块 ---\n",
                "# a. 加载配置\n",
                "config = load_and_merge_configs_for_notebook()\n",
                "\n",
                "# b. 手动加载所有模块\n",
                "print(\"--- 正在加载所有项目模块... ---\")\n",
                "try:\n",
                "    from main_train import (\n",
                "        run_all_data_pipeline, run_preprocess_l3_cache, run_hpo_train,\n",
                "        run_all_models_train, run_performance_evaluation, run_results_visualization,\n",
                "    )\n",
                "    from data_process.get_data import initialize_apis, shutdown_apis, get_full_feature_df, get_latest_global_data\n",
                "    from data_process.save_data import run_data_pipeline, get_processed_data_path\n",
                "    from model.build_models import run_training_for_ticker\n",
                "    from utils.hpo_utils import run_hpo_for_ticker\n",
                "    from model.builders.model_fuser import ModelFuser\n",
                "    from model.builders.lgbm_builder import LGBMBuilder\n",
                "    from model.builders.lstm_builder import LSTMBuilder, LSTMModel\n",
                "    from model.builders.tabtransformer_builder import TabTransformerBuilder, TabTransformerModel\n",
                "    from risk_management.risk_manager import RiskManager\n",
                "    from utils.date_utils import resolve_data_pipeline_dates\n",
                "    from utils.encoding_utils import encode_categorical_features\n",
                "    from utils.file_utils import find_latest_artifact_paths\n",
                "    from utils.ml_utils import walk_forward_split\n",
                "    print(\"INFO: 项目模块导入成功。\")\n",
                "except ImportError as e:\n",
                "    raise ImportError(f\"模块导入失败，请确保 Notebook 的运行目录在项目根目录。错误: {e}\")\n",
                "\n",
                "# c. 构建 modules 字典\n",
                "modules = {\n",
                "    'initialize_apis': initialize_apis, 'shutdown_apis': shutdown_apis,\n",
                "    'get_full_feature_df': get_full_feature_df, 'get_latest_global_data': get_latest_global_data,\n",
                "    'run_data_pipeline': run_data_pipeline, 'get_processed_data_path': get_processed_data_path,\n",
                "    'run_training_for_ticker': run_training_for_ticker, 'run_hpo_for_ticker': run_hpo_for_ticker,\n",
                "    'ModelFuser': ModelFuser, 'LGBMBuilder': LGBMBuilder, 'LSTMBuilder': LSTMBuilder, 'LSTMModel': LSTMModel,\n",
                "    'TabTransformerBuilder': TabTransformerBuilder, 'TabTransformerModel': TabTransformerModel,\n",
                "    'RiskManager': RiskManager,\n",
                "    'resolve_data_pipeline_dates': resolve_data_pipeline_dates,\n",
                "    'encode_categorical_features': encode_categorical_features,\n",
                "    'find_latest_artifact_paths': find_latest_artifact_paths,\n",
                "    'walk_forward_split': walk_forward_split,\n",
                "    'pd': pd, 'torch': torch, 'joblib': joblib, 'tqdm': tqdm, 'StandardScaler': StandardScaler, 'Path': Path, 'yaml': yaml, 'json': json\n",
                "}\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **阶段一：数据准备与特征工程**"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "--- INFO: 日期模式 -> 使用最新日期 ---\n",
                        "=== 阶段一：数据准备与特征工程 ===\n",
                        "INFO: 已启用动态日期模式，将使用今天的日期 '2025-10-28' 作为 end_date。\n",
                        "INFO: 日期已解析. Start Date: 2010-10-28, End Date: 2025-10-28\n",
                        "INFO: 正在尝试登录 Baostock...\n",
                        "login success!\n",
                        "INFO: Baostock API 登录成功。\n",
                        "INFO: 未在配置中提供有效的 Tushare Token，将跳过 Tushare 相关数据。\n",
                        "开始执行数据管道协调任务...\n",
                        "WARNNING: 股票池为空，无需处理。\n",
                        "logout success!\n",
                        "INFO: Baostock API 已成功登出.\n",
                        "--- 阶段 1 成功完成。 ---\n"
                    ]
                }
            ],
            "source": [
                "USE_LATEST_DATE = True\n",
                "if config and modules:\n",
                "    print(f\"--- INFO: 日期模式 -> {'使用最新日期' if USE_LATEST_DATE else '使用配置文件中的固定日期'} ---\")\n",
                "    run_all_data_pipeline(config, modules, use_today_as_end_date=USE_LATEST_DATE)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# **阶段二：模型训练与评估**"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.1 数据预加载与全局预处理 (L3 缓存)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== 工作流阶段 2.1：为模型预处理数据 (L3 缓存) ===\n",
                        "INFO: 开始执行预处理流程 (分块保存模式)...\n",
                        "\n",
                        "--- INFO: L3 缓存文件已在磁盘上准备就绪。 ---\n",
                        "--- 阶段 2.1 成功完成。 ---\n"
                    ]
                }
            ],
            "source": [
                "if config and modules:\n",
                "    # force_reprocess=True/False 可以控制是否重建缓存\n",
                "    run_preprocess_l3_cache(config, modules, force_reprocess=False)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.2 超参数优化"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "RUN_HPO = False\n",
                "if RUN_HPO and config and modules:\n",
                "    run_hpo_train(config, modules)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.3 模型训练"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "=== 工作流阶段 2.3：训练所有模型 ===\n",
                        "ERROR: 配置为空或股票池为空，无法训练模型。\n"
                    ]
                }
            ],
            "source": [
                "if config and modules:\n",
                "    all_ic_history = run_all_models_train(\n",
                "        config, \n",
                "        modules,  \n",
                "        force_retrain_base=False, \n",
                "        force_retrain_fuser=True\n",
                "    )"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### 2.4 结果聚合、评估与可视化"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "if config and modules and 'all_ic_history' in locals() and all_ic_history:\n",
                "    # 调用核心引擎中的评估和可视化函数\n",
                "    evaluation_summary, backtest_summary, final_eval_df = run_performance_evaluation(config, modules, all_ic_history)\n",
                "    \n",
                "    # 只有在有结果时才进行可视化\n",
                "    if evaluation_summary is not None or backtest_summary is not None:\n",
                "        run_results_visualization(config, modules, evaluation_summary, backtest_summary, final_eval_df)\n",
                "    else: print('无可视化结果')"
            ]
        }
    ],
    "metadata": {
        "...": "...",
        "kernelspec": {
            "display_name": ".venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 4
}
