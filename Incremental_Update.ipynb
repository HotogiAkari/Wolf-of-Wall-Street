{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型增量更新与每日预测引擎 (批量版)\n",
    "\n",
    "---\n",
    "\n",
    "### **目标**\n",
    "本 Notebook 是项目的**每日自动化运行脚本**。它会遍历配置文件中定义的所有股票，为每一只成功训练过模型的股票执行在线学习（热更新），并生成新的交易信号。\n",
    "\n",
    "### **工作流程**\n",
    "1.  **环境设置**: 导入库，加载配置。\n",
    "2.  **主循环 (遍历股票)**: 对股票池中的每一只股票，执行以下步骤：\n",
    "    a. **加载模型**: 加载该股票的基础模型 (LGBM, LSTM) 和融合模型 (Fuser)。如果任何模型缺失，则跳过该股票。\n",
    "    b. **获取增量数据**: 智能地获取从上次批量训练至今的所有新数据。\n",
    "    c. **执行增量训练**: 批量生成“历史预测”与“真实标签”，对融合模型进行 `partial_train`。\n",
    "    d. **生成今日新预测**: 使用更新后的融合模型，生成用于次日交易的决策建议。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置与导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Project modules imported successfully.\n",
      "SUCCESS: Config loaded from 'configs/config.yaml'.\n"
     ]
    }
   ],
   "source": [
    "import sys, yaml, pandas as pd, joblib, torch, torch.nn as nn, numpy as np, json\n",
    "from pathlib import Path\n",
    "from tqdm.autonotebook import tqdm\n",
    "\n",
    "# --- 模块导入 ---\n",
    "try:\n",
    "    from data_process.get_data import initialize_apis, shutdown_apis, get_full_feature_df\n",
    "    from model_builders.model_fuser import ModelFuser\n",
    "    from model_builders.lstm_builder import LSTMModel\n",
    "    print(\"INFO: Project modules imported successfully.\")\n",
    "except ImportError as e:\n",
    "    print(f\"WARNNING: Import failed: {e}. Adding project root...\")\n",
    "    project_root = str(Path().resolve()); sys.path.append(project_root) if project_root not in sys.path else None\n",
    "    from data_process.get_data import initialize_apis, shutdown_apis, get_full_feature_df\n",
    "    from model_builders.model_fuser import ModelFuser\n",
    "    from model_builders.lstm_builder import LSTMModel\n",
    "    print(\"INFO: Re-imported successfully.\")\n",
    "\n",
    "# --- 加载配置文件 ---\n",
    "CONFIG_PATH = 'configs/config.yaml'\n",
    "try:\n",
    "    with open(CONFIG_PATH, 'r', encoding='utf-8') as f: config = yaml.safe_load(f)\n",
    "    print(f\"SUCCESS: Config loaded from '{CONFIG_PATH}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Config file not found.\"); config = {}\n",
    "\n",
    "# --- 提取核心配置块 ---\n",
    "if config:\n",
    "    global_settings = config.get('global_settings', {})\n",
    "    stocks_to_process = config.get('stocks_to_process', [])\n",
    "    models_to_train = global_settings.get('models_to_train', ['lgbm', 'lstm'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 批量增量更新与预测主循环"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09099f4ae8224c819b4fecf25765d5b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "批量更新模型:   0%|          | 0/11 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNNING: 在路径 'models\\000001.SZ' 下未找到 平安银行 的 LGBM 模型文件。\n",
      "SUCCESS: 融合构件已加载。\n",
      "WARNNING: 平安银行 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\601606.SH' 下未找到 长城军工 的 LGBM 模型文件。\n",
      "INFO: 未找到已训练的融合模型文件，将使用新初始化的模型。\n",
      "WARNNING: 长城军工 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\000100.SZ' 下未找到 TCL科技 的 LGBM 模型文件。\n",
      "SUCCESS: 融合构件已加载。\n",
      "WARNNING: TCL科技 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\000426.SZ' 下未找到 兴业矿业 的 LGBM 模型文件。\n",
      "INFO: 未找到已训练的融合模型文件，将使用新初始化的模型。\n",
      "WARNNING: 兴业矿业 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\002083.SZ' 下未找到 孚日股份 的 LGBM 模型文件。\n",
      "SUCCESS: 融合构件已加载。\n",
      "WARNNING: 孚日股份 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\000150.SZ' 下未找到 宜华健康 的 LGBM 模型文件。\n",
      "SUCCESS: 融合构件已加载。\n",
      "WARNNING: 宜华健康 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\300013.SZ' 下未找到 新宁物流 的 LGBM 模型文件。\n",
      "INFO: 未找到已训练的融合模型文件，将使用新初始化的模型。\n",
      "WARNNING: 新宁物流 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\300242.SZ' 下未找到 佳云科技 的 LGBM 模型文件。\n",
      "SUCCESS: 融合构件已加载。\n",
      "WARNNING: 佳云科技 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\600301.SH' 下未找到 ST南化 的 LGBM 模型文件。\n",
      "SUCCESS: 融合构件已加载。\n",
      "WARNNING: ST南化 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\002006.SZ' 下未找到 精功科技 的 LGBM 模型文件。\n",
      "SUCCESS: 融合构件已加载。\n",
      "WARNNING: 精功科技 的模型构件不完整，跳过增量更新。\n",
      "WARNNING: 在路径 'models\\300242.SZ' 下未找到 佳云科技 的 LGBM 模型文件。\n",
      "SUCCESS: 融合构件已加载。\n",
      "WARNNING: 佳云科技 的模型构件不完整，跳过增量更新。\n",
      "\n",
      "WARNNING: 未能为任何股票生成有效预测。\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在目前儲存格或上一個儲存格中執行程式碼時，Kernel 已損毀。\n",
      "\u001b[1;31m請檢閱儲存格中的程式碼，找出失敗的可能原因。\n",
      "\u001b[1;31m如需詳細資訊，請按一下<a href='https://aka.ms/vscodeJupyterKernelCrash'>這裡</a>。\n",
      "\u001b[1;31m如需詳細資料，請檢視 Jupyter <a href='command:jupyter.viewOutput'>記錄</a>。"
     ]
    }
   ],
   "source": [
    "if config and stocks_to_process:\n",
    "    stock_iterator = tqdm(stocks_to_process, desc=\"批量更新模型\")\n",
    "    all_predictions_summary = []\n",
    "\n",
    "    for stock_info in stock_iterator:\n",
    "        ticker = stock_info.get('ticker')\n",
    "        keyword = stock_info.get('keyword', ticker)\n",
    "        stock_iterator.set_description(f\"Processing {keyword}\")\n",
    "\n",
    "        if not ticker: continue\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2.1 加载所有模型\n",
    "        # ======================================================================\n",
    "        base_models, base_scalers = {}, {}\n",
    "        all_models_loaded = True\n",
    "        \n",
    "        # 直接从顶层的 global_settings 字典中获取 model_dir\n",
    "        model_dir = Path(config.get('global_settings', {}).get('model_dir', 'models')) / ticker\n",
    "\n",
    "        # 动态确定需要加载的模型\n",
    "        models_to_load_for_this_stock = ['lgbm']\n",
    "        use_lstm_for_this_stock = stock_info.get('use_lstm')\n",
    "        if use_lstm_for_this_stock is None: use_lstm_for_this_stock = global_settings.get('use_lstm_globally', True)\n",
    "        if use_lstm_for_this_stock: models_to_load_for_this_stock.append('lstm')\n",
    "        \n",
    "        for model_type in models_to_load_for_this_stock:\n",
    "            model_files = sorted(model_dir.glob(f\"{model_type}_model_*.p*t\"))\n",
    "            if not model_files:\n",
    "                print(f\"WARNNING: 在路径 '{model_dir}' 下未找到 {keyword} 的 {model_type.upper()} 模型文件。\")\n",
    "                all_models_loaded = False; break\n",
    "            \n",
    "            latest_model_file = model_files[-1]\n",
    "            version_timestamp = latest_model_file.stem.split('_')[-1]\n",
    "            latest_scaler_file = model_dir / f\"{model_type}_scaler_{version_timestamp}.pkl\"\n",
    "\n",
    "            try:\n",
    "                if model_type == 'lgbm':\n",
    "                    base_models[model_type] = joblib.load(latest_model_file)\n",
    "                elif model_type == 'lstm':\n",
    "                    # input_size 将在稍后获取数据时动态确定\n",
    "                    base_models[model_type] = {'path': latest_model_file, 'config': stock_info}\n",
    "                \n",
    "                base_scalers[model_type] = joblib.load(latest_scaler_file)\n",
    "            except Exception as e:\n",
    "                print(f\"ERROR: 加载 {keyword} 的 {model_type.upper()} 构件失败: {e}\")\n",
    "                all_models_loaded = False; break\n",
    "        \n",
    "        fuser = ModelFuser(ticker, config)\n",
    "        if not fuser.load(): all_models_loaded = False\n",
    "\n",
    "        if not all_models_loaded:\n",
    "            print(f\"WARNNING: {keyword} 的模型构件不完整，跳过增量更新。\")\n",
    "            continue\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2.2 获取增量数据\n",
    "        # ======================================================================\n",
    "        incremental_df = None\n",
    "        new_data_for_update = None\n",
    "        try:\n",
    "            initialize_apis(config)\n",
    "            \n",
    "            last_train_date = None\n",
    "            if fuser.meta_path.exists():\n",
    "                with open(fuser.meta_path, 'r', encoding='utf-8') as f: meta_info = json.load(f)\n",
    "                last_train_date = pd.to_datetime(meta_info.get('trained_at')).date()\n",
    "            \n",
    "            if last_train_date is None: last_train_date = pd.Timestamp.now().date() - pd.DateOffset(months=3)\n",
    "\n",
    "            inc_config = config.copy()\n",
    "            inc_config['strategy_config']['earliest_start_date'] = last_train_date.strftime('%Y-%m-%d')\n",
    "            inc_config['strategy_config']['end_date'] = pd.Timestamp.now().strftime('%Y-%m-%d')\n",
    "            \n",
    "            incremental_df = get_full_feature_df(ticker, inc_config, keyword=keyword, prediction_mode=False) # 使用 False 以确保日期被尊重\n",
    "        finally:\n",
    "            shutdown_apis()\n",
    "        \n",
    "        if incremental_df is not None and len(incremental_df) > 1:\n",
    "            label_col = config.get('global_settings', {}).get('label_alpha', 'label_return')\n",
    "            feature_cols = [c for c in incremental_df.columns if c != label_col and not c.startswith('future_')]\n",
    "            \n",
    "            # 动态加载 LSTM 模型\n",
    "            if 'lstm' in base_models:\n",
    "                lstm_model_info = base_models['lstm']\n",
    "                lstm_cfg = {**config.get('default_model_params',{}), **lstm_model_info['config']}.get('lstm_params',{})\n",
    "                model_instance = LSTMModel(input_size=len(feature_cols), hidden_size_1=lstm_cfg.get('units_1',64), hidden_size_2=lstm_cfg.get('units_2',32), dropout=lstm_cfg.get('dropout',0.2))\n",
    "                model_instance.load_state_dict(torch.load(lstm_model_info['path'])); model_instance.eval()\n",
    "                base_models['lstm'] = model_instance\n",
    "            \n",
    "            X_incremental = incremental_df[feature_cols]\n",
    "            y_true_incremental = incremental_df[label_col]\n",
    "            \n",
    "            preds_lgbm = base_scalers['lgbm'].transform(X_incremental)\n",
    "            preds_lgbm = base_models['lgbm']['q_0.5'].predict(preds_lgbm)\n",
    "            \n",
    "            preds_dict_for_update = {'pred_lgbm': preds_lgbm}\n",
    "\n",
    "            if 'lstm' in base_models:\n",
    "                preds_lstm = []\n",
    "                seq_len = lstm_cfg.get('sequence_length', 60)\n",
    "                for i in range(len(X_incremental)):\n",
    "                    pseudo_sequence_df = pd.concat([X_incremental.iloc[i:i+1]] * seq_len, ignore_index=True)\n",
    "                    X_scaled_lstm = base_scalers['lstm'].transform(pseudo_sequence_df)\n",
    "                    X_tensor_lstm = torch.from_numpy(X_scaled_lstm).unsqueeze(0).float()\n",
    "                    with torch.no_grad(): preds_lstm.append(base_models['lstm'](X_tensor_lstm).item())\n",
    "                preds_dict_for_update['pred_lstm'] = preds_lstm\n",
    "\n",
    "            new_data_for_update = pd.DataFrame(preds_dict_for_update, index=X_incremental.index)\n",
    "            new_data_for_update['y_true'] = y_true_incremental\n",
    "            new_data_for_update.dropna(inplace=True)\n",
    "            \n",
    "            if new_data_for_update.empty: new_data_for_update = None\n",
    "        \n",
    "        # ======================================================================\n",
    "        # 2.3 执行增量训练\n",
    "        # ======================================================================\n",
    "        if new_data_for_update is not None and not new_data_for_update.empty:\n",
    "            fuser.partial_train(new_data_for_update)\n",
    "        else:\n",
    "            print(f\"INFO: {keyword} 没有可用的新数据进行增量训练。\")\n",
    "\n",
    "        # ======================================================================\n",
    "        # 2.4 生成今日新预测\n",
    "        # ======================================================================\n",
    "        if incremental_df is not None and len(incremental_df) > 0:\n",
    "            today_features = incremental_df.iloc[-1:]\n",
    "            X_today = today_features[feature_cols]\n",
    "            \n",
    "            X_scaled_lgbm = base_scalers['lgbm'].transform(X_today)\n",
    "            pred_lgbm_today = base_models['lgbm']['q_0.5'].predict(X_scaled_lgbm)[0]\n",
    "            \n",
    "            preds_today = {'pred_lgbm': pred_lgbm_today}\n",
    "\n",
    "            if 'lstm' in base_models:\n",
    "                lstm_cfg = {**config.get('default_model_params',{}), **stock_info}.get('lstm_params',{})\n",
    "                seq_len = lstm_cfg.get('sequence_length', 60)\n",
    "                pseudo_sequence = pd.concat([X_today] * seq_len, ignore_index=True)\n",
    "                X_scaled_lstm = base_scalers['lstm'].transform(pseudo_sequence)\n",
    "                X_tensor_lstm = torch.from_numpy(X_scaled_lstm).unsqueeze(0).float()\n",
    "                with torch.no_grad(): pred_lstm_today = base_models['lstm'](X_tensor_lstm).item()\n",
    "                preds_today['pred_lstm'] = pred_lstm_today\n",
    "            \n",
    "            final_signal = fuser.predict(preds_today)\n",
    "            direction = '看涨 (BUY)' if final_signal > 0 else '看跌 (SELL)'\n",
    "            \n",
    "            all_predictions_summary.append({'股票': keyword, '代码': ticker, '信号方向': direction, '信号强度': final_signal})\n",
    "            \n",
    "            # (可选) 打印单只股票的详细报告\n",
    "            print(f\"--- 为 {keyword} 生成的明日交易建议 ---\")\n",
    "            print(f\"核心观点: {direction}, 信号强度: {final_signal:.4%}\")\n",
    "\n",
    "    # --- 循环结束后，显示所有预测的汇总 ---\n",
    "    if all_predictions_summary:\n",
    "        print(\"\\n\" + \"=\"*80)\n",
    "        print(\"--- 所有股票当日预测信号汇总 ---\")\n",
    "        summary_df = pd.DataFrame(all_predictions_summary)\n",
    "        display(summary_df.style.format({'信号强度': '{:+.4%}'}).set_index(['股票', '代码']))\n",
    "        print(\"=\"*80)\n",
    "    else:\n",
    "        print(\"\\nWARNNING: 未能为任何股票生成有效预测。\")\n",
    "\n",
    "else:\n",
    "    print(\"ERROR: 配置文件或股票池为空。\")"
   ]
  }
 ],
 "metadata": {
  "...": "...",
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
