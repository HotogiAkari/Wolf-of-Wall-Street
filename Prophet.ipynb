{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型融合预测与交易决策引擎\n",
    "\n",
    "---\n",
    "\n",
    "### **目标**\n",
    "本 Notebook 是整个项目的**应用终端**。它的核心职责是模拟实盘环境，对指定的股票执行完整的“数据-预测-决策”流程。\n",
    "\n",
    "### **工作流程**\n",
    "1.  **环境设置与目标选定**: 导入库，加载配置，并指定今天要进行预测的目标股票。\n",
    "2.  **加载已训练构件**: \n",
    "    - 自动查找并加载目标股票**最新版本**的 LGBM 和 LSTM 模型。\n",
    "    - 加载对应的 `StandardScaler`。\n",
    "    - 加载两个模型完整的 IC 历史记录，用于动态权重计算。\n",
    "3.  **获取最新特征**: 调用数据处理流水线，获取截至**今天**的最新一行特征数据。\n",
    "4.  **独立模型预测**: 分别使用 LGBM 和 LSTM 模型对最新特征进行预测。\n",
    "5.  **动态权重融合**: \n",
    "    - 基于 IC 历史计算出 LGBM 和 LSTM 当前的动态权重。\n",
    "    - 对两个模型的预测值（经过 Z-score 标准化）进行加权融合，得到最终的预测信号。\n",
    "6.  **风险审批与决策输出**: \n",
    "    - 将融合后的信号提交给 `RiskManager` 进行最终审批（如重复信号检查）。\n",
    "    - 根据审批结果，输出明确的交易决策（如：**【批准开仓：买入】** 或 **【信号被拒：重复信号】**）。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 环境设置与目标选定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, yaml, json, numpy as np, pandas as pd, joblib, torch\n",
    "from pathlib import Path\n",
    "from IPython.display import display\n",
    "\n",
    "# --- 模块导入 ---\n",
    "try:\n",
    "    from data_process.get_data import initialize_apis, shutdown_apis, get_full_feature_df\n",
    "    from model.builders.lstm_builder import LSTMModel\n",
    "    from model.builders.model_fuser import ModelFuser\n",
    "    from risk_management.risk_manager import RiskManager, OrderStatus\n",
    "    print(\"INFO: 项目模型导入成功.\")\n",
    "except ImportError as e:\n",
    "    print(f\"WARNNING: 导入失败: {e}. 正在添加项目根目录...\")\n",
    "    project_root = str(Path().resolve()); sys.path.append(project_root) if project_root not in sys.path else None\n",
    "    from data_process.get_data import initialize_apis, shutdown_apis, get_full_feature_df\n",
    "    from model.builders.lstm_builder import LSTMModel\n",
    "    from model.builders.model_fuser import ModelFuser\n",
    "    from risk_management.risk_manager import RiskManager, OrderStatus\n",
    "    print(\"INFO: 导入成功.\")\n",
    "\n",
    "# --- 加载配置文件 ---\n",
    "CONFIG_PATH = 'configs/config.yaml'\n",
    "try:\n",
    "    with open(CONFIG_PATH, 'r', encoding='utf-8') as f: config = yaml.safe_load(f)\n",
    "    print(f\"SUCCESS: Config loaded from '{CONFIG_PATH}'.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"ERROR: Config file not found.\"); config = {}\n",
    "\n",
    "if config:\n",
    "    db_path = config.get('global_settings', {}).get('order_history_db', 'order_history.db')\n",
    "    risk_manager = RiskManager(db_path=db_path)\n",
    "    print(f\"--- INFO: RiskManager 已初始化，使用数据库: {db_path} ---\")\n",
    "else:\n",
    "    risk_manager = None\n",
    "    print(\"WARNNING: Config 为空，RiskManager 未初始化。\")\n",
    "\n",
    "# --- 设定要分析的股票 --- \n",
    "TARGET_TICKER = '600519.SH'\n",
    "stock_info = next((s for s in config.get('stocks_to_process', []) if s['ticker'] == TARGET_TICKER), None)\n",
    "if stock_info:\n",
    "    TARGET_KEYWORD = stock_info.get('keyword', TARGET_TICKER)\n",
    "    print(f\"--- 目标股票已设定: {TARGET_KEYWORD} ({TARGET_TICKER}) ---\")\n",
    "else:\n",
    "    print(f\"ERROR: 在配置文件中未找到股票 {TARGET_TICKER} 的信息！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 加载已训练构件 (模型, Scaler, IC历史)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {}\n",
    "scalers = {}\n",
    "ic_histories = {}\n",
    "all_components_loaded = False\n",
    "\n",
    "if stock_info:\n",
    "    model_dir = Path(config.get('global_settings', {}).get('model_dir', 'models')) / TARGET_TICKER\n",
    "    models_to_load = config.get('global_settings', {}).get('models_to_train', ['lgbm', 'lstm'])\n",
    "    \n",
    "    all_found = True\n",
    "    for model_type in models_to_load:\n",
    "        print(f\"\\n--- 正在加载 {model_type.upper()} 的构件...\")\n",
    "        # 查找最新版本的模型\n",
    "        model_files = sorted(model_dir.glob(f\"{model_type}_model_*.p*t\")) # .pkl or .pt\n",
    "        if not model_files:\n",
    "            print(f\"ERROR: 未找到 {model_type.upper()} 的模型文件。请先运行训练流程。\")\n",
    "            all_found = False; continue\n",
    "        \n",
    "        latest_model_file = model_files[-1]\n",
    "        version_timestamp = latest_model_file.stem.split('_')[-1]\n",
    "        latest_scaler_file = model_dir / f\"{model_type}_scaler_{version_timestamp}.pkl\"\n",
    "        ic_history_file = model_dir / f\"{model_type}_ic_history.csv\"\n",
    "\n",
    "        # 加载模型、Scaler 和 IC 历史\n",
    "        try:\n",
    "            if model_type == 'lgbm':\n",
    "                models[model_type] = joblib.load(latest_model_file)\n",
    "            \n",
    "            # (修改开始)\n",
    "            elif model_type == 'lstm':\n",
    "                # 1. (新增) 查找并加载元数据文件\n",
    "                latest_meta_file = model_dir / f\"{model_type}_meta_{version_timestamp}.json\"\n",
    "                if not latest_meta_file.exists():\n",
    "                    raise FileNotFoundError(f\"未找到 LSTM 的元数据文件: {latest_meta_file}\")\n",
    "                \n",
    "                with open(latest_meta_file, 'r', encoding='utf-8') as f:\n",
    "                    lstm_metadata = json.load(f)\n",
    "                \n",
    "                input_size = lstm_metadata.get('input_size')\n",
    "                if not input_size:\n",
    "                    raise ValueError(\"元数据文件中缺少 'input_size'。\")\n",
    "                \n",
    "                # 2. 使用元数据动态实例化模型\n",
    "                lstm_cfg = {**config.get('default_model_params',{}), **stock_info}.get('lstm_params',{})\n",
    "                \n",
    "                print(f\"  - INFO: 从元数据加载 input_size = {input_size}\")\n",
    "                model_instance = LSTMModel(\n",
    "                    input_size=input_size,  # <-- 使用动态加载的值\n",
    "                    hidden_size_1=lstm_cfg.get('units_1', 64), \n",
    "                    hidden_size_2=lstm_cfg.get('units_2', 32), \n",
    "                    dropout=lstm_cfg.get('dropout', 0.2)\n",
    "                )\n",
    "                \n",
    "                # 3. 加载模型权重\n",
    "                model_instance.load_state_dict(torch.load(latest_model_file))\n",
    "                model_instance.eval() # 设为评估模式\n",
    "                models[model_type] = model_instance\n",
    "            ic_histories[model_type] = pd.read_csv(ic_history_file, index_col=0, parse_dates=True)\n",
    "            print(f\"SUCCESS: 成功加载 {model_type.upper()} 版本 '{version_timestamp}' 的模型、Scaler 和 IC 历史。\")\n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"ERROR: 加载失败，找不到文件: {e}\")\n",
    "            all_found = False\n",
    "        except Exception as e:\n",
    "            print(f\"ERROR: 加载时发生未知错误: {e}\")\n",
    "            all_found = False\n",
    "\n",
    "    if all_found and len(models) == len(models_to_load):\n",
    "        all_components_loaded = True\n",
    "        print(\"\\n--- 所有必需的模型构件已成功加载！---\")\n",
    "else:\n",
    "    print(\"ERROR: 股票信息未定义，无法加载模型。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 获取最新特征数据\n",
    "\n",
    "调用数据流水线，获取截至**今天**的最新特征。我们只关心返回的数据框的**最后一行**。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet.ipynb -> \"3. 获取最新特征数据\"\n",
    "\n",
    "latest_features = None\n",
    "historical_sequence_for_lstm = None\n",
    "full_feature_df_for_risk = None\n",
    "\n",
    "if all_components_loaded:\n",
    "    try:\n",
    "        initialize_apis(config)\n",
    "        \n",
    "        # 动态计算需要的历史数据长度\n",
    "        lstm_params = config.get('default_model_params', {}).get('lstm_params', {})\n",
    "        seq_len = lstm_params.get('sequence_length', 60)\n",
    "        \n",
    "        # 调整数据获取的起始日期，以确保能拿到完整的序列\n",
    "        # 我们需要一个比 seq_len 更长的历史窗口来确保数据质量和处理 NaN\n",
    "        required_lookback_days = seq_len + 120 # 例如，多获取约半年的数据作为 buffer\n",
    "\n",
    "        # 创建一个临时的 config 副本进行修改，避免污染全局 config\n",
    "        pred_config = config.copy()\n",
    "        end_date_dt = pd.to_datetime(pred_config['strategy_config']['end_date'])\n",
    "        required_start_date = (end_date_dt - pd.DateOffset(days=required_lookback_days)).strftime('%Y-%m-%d')\n",
    "        \n",
    "        # 确保 earliest_start_date 不会比我们需要的晚\n",
    "        pred_config['strategy_config']['earliest_start_date'] = min(\n",
    "            pred_config['strategy_config']['earliest_start_date'],\n",
    "            required_start_date\n",
    "        )\n",
    "\n",
    "        full_feature_df_for_risk = get_full_feature_df(\n",
    "            TARGET_TICKER, \n",
    "            pred_config, # 使用修改后的临时配置\n",
    "            keyword=TARGET_KEYWORD, \n",
    "            prediction_mode=True\n",
    "        )\n",
    "        \n",
    "        # 检查返回的数据是否足够长\n",
    "        if full_feature_df_for_risk is not None and len(full_feature_df_for_risk) >= seq_len:\n",
    "            # (修改) 为 LGBM 获取最后一行\n",
    "            latest_features = full_feature_df_for_risk.iloc[-1:]\n",
    "            \n",
    "            # (修改) 为 LSTM 提取真实的最后 N 天数据\n",
    "            historical_sequence_for_lstm = full_feature_df_for_risk.iloc[-seq_len:]\n",
    "            \n",
    "            print(f\"SUCCESS: 成功获取 {TARGET_KEYWORD} 的最新特征数据 (日期: {latest_features.index[0].date()})。\")\n",
    "            print(f\"  - INFO: 已为 LSTM 准备好长度为 {len(historical_sequence_for_lstm)} 的真实历史序列。\")\n",
    "            display(latest_features)\n",
    "        else:\n",
    "            print(f\"ERROR: 获取到的数据长度不足 {seq_len}，无法为 LSTM 生成有效的输入序列。\")\n",
    "            \n",
    "    finally:\n",
    "        shutdown_apis()\n",
    "else:\n",
    "    print(\"模型构件加载不完整，跳过数据获取。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 独立模型预测"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prophet.ipynb -> \"4. 独立模型预测\"\n",
    "\n",
    "predictions = {}\n",
    "lgbm_quantile_preds = {}\n",
    "\n",
    "if latest_features is not None:\n",
    "    label_col = config.get('global_settings', {}).get('label_column', 'label_return')\n",
    "    feature_cols = [c for c in latest_features.columns if c != label_col]\n",
    "    X_latest = latest_features[feature_cols]\n",
    "\n",
    "    # --- LGBM 预测 (现在预测所有分位数) ---\n",
    "    if 'lgbm' in models:\n",
    "        X_scaled_lgbm = scalers['lgbm'].transform(X_latest)\n",
    "        \n",
    "        # 循环遍历所有已训练的分位数模型\n",
    "        for name, model in models['lgbm'].items():\n",
    "            pred = model.predict(X_scaled_lgbm)[0]\n",
    "            lgbm_quantile_preds[name] = pred\n",
    "            # 仍然将中位数作为 lgbm 的主要“点预测”\n",
    "            if name == 'q_0.5':\n",
    "                predictions['lgbm'] = pred\n",
    "        \n",
    "        print(\"--- LGBM 分位数预测结果 ---\")\n",
    "        for name, pred in lgbm_quantile_preds.items():\n",
    "            print(f\"  - {name} (预期收益率): {pred:.6f}\")\n",
    "\n",
    "    # --- LSTM 预测 ---\n",
    "    if 'lstm' in models and historical_sequence_for_lstm is not None:\n",
    "        # 确保使用正确的特征列\n",
    "        X_sequence_lstm = historical_sequence_for_lstm[feature_cols]\n",
    "\n",
    "        # 使用真实的、连续的历史序列进行标准化\n",
    "        X_scaled_lstm = scalers['lstm'].transform(X_sequence_lstm)\n",
    "        \n",
    "        # 将其转换为 LSTM 需要的 3D Tensor ([batch_size, seq_len, num_features])\n",
    "        # unsqueeze(0) 在最前面增加一个 batch 维度 (batch_size=1)\n",
    "        X_tensor_lstm = torch.from_numpy(X_scaled_lstm).unsqueeze(0).float() \n",
    "        \n",
    "        with torch.no_grad():\n",
    "            pred_lstm = models['lstm'](X_tensor_lstm).item()\n",
    "        predictions['lstm'] = pred_lstm\n",
    "        print(f\"\\\\nLSTM 原始预测值 (基于真实历史序列): {pred_lstm:.6f}\")\n",
    "else:\n",
    "    print(\"最新特征数据不可用，无法进行预测。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 动态权重融合"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fused_prediction = None\n",
    "\n",
    "# --- (新增) 全局 Fuser 实例管理 ---\n",
    "# 我们在 Notebook 的全局作用域中创建或获取 fuser 实例\n",
    "# 如果 fuser_instance 还不存在，就创建它\n",
    "if 'fuser_instance' not in locals():\n",
    "    print(\"--- INFO: 首次运行，正在初始化并加载 ModelFuser... ---\")\n",
    "    fuser_instance = ModelFuser(TARGET_TICKER, config)\n",
    "    fuser_instance.load() # 加载已训练的模型\n",
    "\n",
    "if 'predictions' in locals() and len(predictions) >= 1: # 即使只有一个模型，也可以继续\n",
    "    print(\"\\\\n--- 开始执行模型融合... ---\")\n",
    "    \n",
    "    if fuser_instance and fuser_instance.is_trained:\n",
    "        # 1. 准备输入\n",
    "        # 我们需要确保 preds_dict 的键与 Fuser 训练时使用的名称完全一致\n",
    "        required_preds = {f'pred_{m}' for m in fuser_instance.meta_model.feature_names_in_}\n",
    "        preds_dict = {f'pred_{model_type}': pred for model_type, pred in predictions.items()}\n",
    "        \n",
    "        # 2. (核心修复) 正确调用 predict 方法\n",
    "        # fuser_instance 内部会自己维护平滑所需的历史预测 self.recent_preds\n",
    "        fused_prediction = fuser_instance.predict(preds_dict)\n",
    "        \n",
    "        print(f\"\\\\n融合后的最终预测信号 (已平滑): {fused_prediction:.6f}\")\n",
    "        \n",
    "        # 3. (可选) 显示 Fuser 内部状态\n",
    "        if hasattr(fuser_instance.meta_model, 'coef_'):\n",
    "            coefs = {name: val for name, val in zip(fuser_instance.meta_model.feature_names_in_, fuser_instance.meta_model.coef_)}\n",
    "            print(f\"  - 融合模型权重 -> {coefs}\")\n",
    "        \n",
    "        print(f\"  - INFO: 当前平滑窗口内的历史预测值: {fuser_instance.recent_preds}\")\n",
    "        \n",
    "    else:\n",
    "        # 如果 Fuser 不可用，回退到简单平均\n",
    "        print(\"WARNNING: ModelFuser 不可用或未训练。回退到对基础模型预测进行简单平均。\")\n",
    "        fused_prediction = np.mean(list(predictions.values()))\n",
    "        print(f\"\\\\n简单平均后的预测信号: {fused_prediction:.6f}\")\n",
    "else:\n",
    "    print(\"模型预测不完整或未执行，无法进行融合。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 风险审批与决策输出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "\n",
    "if 'risk_manager' in locals() and risk_manager is None:\n",
    "    print(\"ERROR: RiskManager 未成功初始化，无法进行风险审批。\")\n",
    "\n",
    "elif fused_prediction is not None:\n",
    "    print(\"\\\\n--- 开始执行风险审批与决策生成 ---\")\n",
    "    \n",
    "    # --- 1. 定义信号与阈值 ---\n",
    "    signal_threshold = config.get('strategy_config', {}).get('signal_threshold', 0.005)\n",
    "    direction_str = 'BUY' if fused_prediction > signal_threshold else ('SELL' if fused_prediction < -signal_threshold else 'HOLD')\n",
    "    trade_price = latest_features['close'].iloc[0] # 假设以最新收盘价作为交易参考价\n",
    "\n",
    "    # 决策报告的初始状态\n",
    "    decision_approved = False\n",
    "    decision_notes = \"信号强度未达到开仓阈值。\"\n",
    "    order_id = None\n",
    "\n",
    "    # --- 2. (核心修复) 提交给 RiskManager 审批 ---\n",
    "    # 只有在明确有开仓意图时才进行审批\n",
    "    if direction_str in ['BUY', 'SELL']:\n",
    "        print(f\"INFO: 检测到开仓信号 '{direction_str}'，强度为 {fused_prediction:.4%}, 提交至 RiskManager 审批...\")\n",
    "        \n",
    "        # 确保 full_feature_df_for_risk 存在\n",
    "        if 'full_feature_df_for_risk' not in locals() or full_feature_df_for_risk is None:\n",
    "            decision_notes = \"ERROR: 缺少用于风险审批的历史市场数据。\"\n",
    "            print(f\"  - {decision_notes}\")\n",
    "        else:\n",
    "            decision_approved, order_id = risk_manager.approve_trade(\n",
    "                ticker=TARGET_TICKER,\n",
    "                direction=direction_str,\n",
    "                price=trade_price,\n",
    "                latest_market_data=full_feature_df_for_risk,\n",
    "                config=config \n",
    "            )\n",
    "\n",
    "            if decision_approved:\n",
    "                decision_notes = f\"信号通过所有风险检查。已创建待处理订单。\"\n",
    "                print(f\"  - SUCCESS: {decision_notes} (Order ID: {order_id})\")\n",
    "            else:\n",
    "                # approve_trade 内部会打印具体拒绝原因 (如重复信号)\n",
    "                decision_notes = \"信号被 RiskManager 拒绝（详情请见上方日志）。\"\n",
    "                print(f\"  - FAILED: {decision_notes}\")\n",
    "    else:\n",
    "        print(\"INFO: 当前信号为 'HOLD'，无需进行开仓审批。\")\n",
    "\n",
    "    # --- 3. 构建并展示最终的决策报告 ---\n",
    "    final_direction = \"看涨 (BUY)\" if direction_str == 'BUY' else (\"看跌 (SELL)\" if direction_str == 'SELL' else \"中性 (HOLD)\")\n",
    "    \n",
    "    # 根据审批结果确定最终状态\n",
    "    trade_action = \"【批准开仓】\" if decision_approved else (\"【信号被拒】\" if direction_str in ['BUY', 'SELL'] else \"【无需操作】\")\n",
    "\n",
    "    report_data = [\n",
    "        ('基础信息', '股票名称', f\"{TARGET_KEYWORD} ({TARGET_TICKER})\"),\n",
    "        ('基础信息', '决策生成时间', pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')),\n",
    "        ('核心观点', '信号方向', final_direction),\n",
    "        ('核心观点', '信号强度', f\"{fused_prediction:+.4%}\"),\n",
    "        ('最终决策', '交易动作', f\"{trade_action} {final_direction if decision_approved else ''}\"),\n",
    "        ('最终决策', '备注', decision_notes),\n",
    "        ('最终决策', '关联订单ID', order_id if order_id else 'N/A'),\n",
    "    ]\n",
    "    report_df = pd.DataFrame(report_data, columns=['类别', '项目', '内容']).set_index(['类别', '项目'])\n",
    "    \n",
    "    # --- 4. 美化与显示 ---\n",
    "    def format_value(s):\n",
    "        idx = s.name[1]\n",
    "        if idx == '信号强度 (预期收益)': return [f'{v:+.2%}' for v in s]\n",
    "        return s\n",
    "        \n",
    "    def color_direction(val):\n",
    "        if '看涨' in str(val): return 'color: red; font-weight: bold'\n",
    "        if '看跌' in str(val): return 'color: green; font-weight: bold'\n",
    "        return ''\n",
    "        \n",
    "    styled_report = (report_df.style\n",
    "        .set_caption(\"投资建议\")\n",
    "        .apply(format_value, axis=1)\n",
    "        .applymap_index(lambda v: 'font-weight: bold;', level=0)\n",
    "        .applymap(color_direction, subset=pd.IndexSlice[('核心观点', '投资方向'), :])\n",
    "        .set_table_styles([ ... ]) # (保留您之前的样式)\n",
    "    )\n",
    "    \n",
    "    display(styled_report)\n",
    "   \n",
    "else:\n",
    "    print(\"无有效融合信号，无法生成投资建议。\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
